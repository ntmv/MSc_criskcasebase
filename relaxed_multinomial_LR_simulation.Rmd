---
title: "Relaxed Lasso Multinomial LR Simulation"
author: "Alexander Romanus"
date: "`r Sys.Date()`"
knit: (function(inputFile, encoding) { 
      out_dir <- '/results/knits';
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), out_dir, paste(runif(1), 'relaxed_simulation.html'))) })
output:
  html_document: 
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
library(casebase)
library(future.apply)
library(glmnet)
#library(mtool)
library(parallelly)
library(timereg)
library(parallel)
library(tictoc)
library(tidyverse)
#library(riskRegression)
library(cmprsk)
library(survsim)
library(caret)
library(Matrix)
library(dplyr)

# Helper functions 
source("/src/helper_functions.R")
```


# Setup simulation
``` {r setup-simulation}
p = 120
n = 400
nfolds = 5
seed = 2023


num_true <- 20
beta1 <- c(rep(0, p))
beta2 <- c(rep(0, p))
nu_ind <- seq(num_true)
# Here out of 20 predictors, 10 should be non-zero 
beta1[nu_ind] <- c(rep(1, 10), rep(0, 10))
beta2[nu_ind] <- c(rep(-1, 10), rep(0, 10))

# Simulate data
sim.data <- cause_hazards_sim(n = n, p = p, nblocks = 4, 
                              beta1 = beta1, beta2 = beta2, rate_cens = 0.25, 
                              h1 = 0.55, h2 = 0.10, gamma1 = 1.5, gamma2 = 1.5)


# Censoring proportion
cen.prop <- c(prop.table(table(sim.data$fstatus)), 0, 0, 0, 0)

# Training-test split 
# We only do this (instead of generating datasets for train and test like Anthony mentioned because it is faster computationally 
# as casebase resamples) + proportion of censoring can be quite random in each run of the simulation so we want to maintain the same in validation and test set
train.index <- caret::createDataPartition(sim.data$fstatus, p = 0.75, list = FALSE)
train <- sim.data[train.index,]
test <- sim.data[-train.index,]
```


# Check final implementation
``` {r test-relaxed-lasso-final}
