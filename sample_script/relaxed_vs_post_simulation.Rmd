---
title: "Relaxed Lasso Glmnet Simulation"
author: "Alexander Romanus"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
library(casebase)
library(future.apply)
library(glmnet)
#library(mtool)
library(parallelly)
library(timereg)
library(parallel)
library(tictoc)
library(tidyverse)
#library(riskRegression)
library(cmprsk)
library(survsim)
library(caret)
library(Matrix)
library(dplyr)

# Helper functions 
source("src/helper_functions.R")
```

# Simulation setup

```{r setting-up-simulation}
generateDataset = function(p, n) {
  beta = c()
  for (i in seq(1:(p+1))) {
    if (i == 1) {
      beta = c(beta, 1)
    }
    else if (i %% 2 == 0) {
      beta = c(beta, 0)
    } else {
      beta = c(beta, 0.5)
    }
  }
  beta = as.matrix(beta)
  beta_neg = -beta
  
  
  zero_ind1 <- which(beta == 0)
  nonzero_ind1 <- which(beta != 0)
  
  
  # Generate X (iid case)
  X <- matrix(rnorm(n*p), nrow = n, ncol = p)
  X = cbind(rep(1, times = n), X)
  
  
  #Generate Y
  epsilon <- rnorm(n, sd = 0.5)
  Y1 = X %*% beta + epsilon
  Y2 = X %*% beta_neg + epsilon
  
  result = list(X = X, Y = Y1)
  return(result)
}
```

``` {r train-test-split, echo=FALSE, include = FALSE}
partitionData = function(x, y) {
  train_index_y = caret::createDataPartition(y, p = 0.80, list = FALSE)

  x_train = x[train_index_y, -1]
  y_train = y[train_index_y]

  x_test = x[-train_index_y, -1]
  y_test = y[-train_index_y]

  result = list(x_train = x_train, y_train = y_train,
                x_test = x_test, y_test = y_test)
  
  return(result)
}
```

# Fits

``` {r different-models-fits, echo=FALSE}
fitAll = function(train_data, response, print_time) {
  fit_Y1 = cv.glmnet(train_data, response, gamma = 0, relax = FALSE)
  relaxed_fit_Y1 = cv.glmnet(train_data, response, gamma = 0, relax = TRUE)
  my_relaxed_fit_Y1 = myRelaxed(train_data, response, FALSE, print_time)
  my_relaxed_fit_cv_Y1 = myRelaxed(train_data, response, TRUE, print_time)
  
  coef_lasso_same_lambda = as.data.frame.matrix(coef(fit_Y1))[-1, ]
  non_zero_coef_lasso_then_OLS_same_lambda = coef_lasso_same_lambda[coef_lasso_same_lambda != 0]
  non_zero_coef_lasso_then_OLS_same_lambda_indeces = which(coef_lasso_same_lambda %in% non_zero_coef_lasso_then_OLS_same_lambda)
  
  lambda_min = fit_Y1$lambda.min
  lambda_1se = fit_Y1$lambda.1se
  
  coefficient_names = colnames(as.data.frame(train_data))
  selected_coefficient_names = coefficient_names[non_zero_coef_lasso_then_OLS_same_lambda_indeces]
  new_train_data = train_data[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
  colnames(new_train_data) = c(selected_coefficient_names)
  
  fit_Y1_post_lasso_lambda_min = glmnet(new_train_data, response, lambda = lambda_min)
  fit_Y1_post_lasso_lambda_1se = glmnet(new_train_data, response, lambda = lambda_1se)
  
  result = list(cv_glmnet = fit_Y1, cv_glmnet_relaxed = relaxed_fit_Y1, my_relaxed = my_relaxed_fit_Y1,
                my_relaxed_cv = my_relaxed_fit_cv_Y1, post_lasso_lambda_min = fit_Y1_post_lasso_lambda_min,
                post_lasso_lambda_1se = fit_Y1_post_lasso_lambda_1se)
  
  return(result)
}
```


``` {r compute-MSEs, echo=FALSE}
computeMSEs = function(resulting_fits, test_data) {
  pred_fit_min = predict(resulting_fits$cv_glmnet, newx = test_data$x_test, s = resulting_fits$cv_glmnet$lambda.min)
  pred_fit_1se = predict(resulting_fits$cv_glmnet, newx = test_data$x_test, s = resulting_fits$cv_glmnet$lambda.1se)
  pred_fit_relaxed_min = predict(resulting_fits$cv_glmnet_relaxed, newx = test_data$x_test, s = resulting_fits$cv_glmnet_relaxed$relaxed$lambda.min)
  pred_fit_relaxed_1se = predict(resulting_fits$cv_glmnet_relaxed, newx = test_data$x_test, s = resulting_fits$cv_glmnet_relaxed$relaxed$lambda.1se)

  
  pred_myRelaxed = predict(resulting_fits$my_relaxed$best_fit, newx = test_data$x_test)
  pred_myRelaxed_cv = predict(resulting_fits$my_relaxed_cv$best_fit, newx = test_data$x_test)

  
  # coefficient_names = colnames(as.data.frame(test_data$x_test))
  # new_x_test = x_test[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
  # colnames(new_x_test) = rownames(as.data.frame.matrix(fit_Y1_post_lasso_lambda_min$beta))
  # pred_fit_post_lasso_min = predict(fit_Y1_post_lasso_lambda_min, newx = new_x_test, s = fit_Y1$lambda.min)
  # 
  # 
  # coefficient_names = colnames(as.data.frame(x_test))
  # new_x_test = x_test[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
  # colnames(new_x_test) = rownames(as.data.frame.matrix(fit_Y1_post_lasso_lambda_1se$beta))
  # pred_fit_post_lasso_1se = predict(fit_Y1_post_lasso_lambda_1se, newx = new_x_test, s = fit_Y1$lambda.1se)
  
  
  # Compute MSE
  mse_min <- sum((pred_fit_min - test_data$y_test)^2)
  mse_1se <- sum((pred_fit_1se - test_data$y_test)^2)
  mse_relaxed_min <- sum((pred_fit_relaxed_min - test_data$y_test)^2)
  mse_relaxed_1se <- sum((pred_fit_relaxed_1se - test_data$y_test)^2)
  mse_myRelaxed <- sum((pred_myRelaxed - test_data$y_test)^2)
  mse_myRelaxed_cv <- sum((pred_myRelaxed_cv - test_data$y_test)^2)
  # mse_post_lasso_min <- sum((pred_fit_post_lasso_min - y1_test)^2)
  # mse_post_lasso_1se <- sum((pred_fit_post_lasso_1se - y1_test)^2)
  
  MSEs = data.frame(matrix(nrow = 6, ncol = 2))
  colnames(MSEs) = c("Model", "Test MSE")
  
  MSE_labels = c("cv.glmnet relax = FALSE, LASSO, lambda min", "cv.glmnet relax = FALSE, LASSO, lambda 1se", 
                       "cv.glmnet relax = TRUE, lambda min", "cv.glmnet relax = TRUE, lambda 1se", 
                       "Relaxed LASSO implementation no CV", "Relaxed LASSO implementation CV")
  
  # print(mse_min)
  # writeLines("")
  # print(mse_1se)
  # writeLines("")
  # print(mse_relaxed_min)
  # writeLines("")
  # print(mse_relaxed_1se)
  # writeLines("")
  # print(mse_myRelaxed)
  # writeLines("")
  # print(mse_myRelaxed_cv)
  # writeLines("")

  MSEs[, 1] = MSE_labels
  # MSEs[, 2] = c(mse_min, mse_1se, mse_relaxed_min, mse_relaxed_1se, mse_myRelaxed, mse_myRelaxed_cv, mse_post_lasso_min, mse_post_lasso_1se)
  MSEs[, 2] = c(mse_min, mse_1se, mse_relaxed_min, mse_relaxed_1se, mse_myRelaxed, mse_myRelaxed_cv)
  
  return(MSEs)
}

```


# Run simulation
``` {r run-sim, warning = FALSE, echo = FALSE}

# dataset = generateDataset(20, 400)
# partitioned_data = partitionData(dataset$X, dataset$Y)
# training_data = partitioned_data[c("x_train", "y_train")]
# test_data = partitioned_data[c("x_test", "y_test")]
# resulting_fits = fitAll(training_data$x_train, training_data$y_train, FALSE)

oneIteration = function(p, n, training_data, test_data, print_time) {
  tryCatch({
    # Fit training data with different models
    resulting_fits = fitAll(training_data$x_train, training_data$y_train, FALSE)
  
    # Get table of coefficient values for each model
    coefficient_names = colnames(as.data.frame(training_data$x_train))
    coefficient_names = c("Model", coefficient_names)
    coefs = formatCoefficientTable(p, n, coefficient_names, resulting_fits, print_time)
  
    # Compute biases
    MSEs = computeMSEs(resulting_fits, test_data)
    

    return(list(coefficient_table = coefs, MSE_table = MSEs))
  },
  error = function(e) {
    #print(e)
  })
}

formatCoefficientTable = function(p, n, coefficient_names, resulting_fits, print_time) {
  model_fit_labels = c("cv.glmnet relax = FALSE, LASSO, lambda min", "cv.glmnet relax = FALSE, LASSO, lambda 1se", 
                       "cv.glmnet relax = TRUE, lambda min", "cv.glmnet relax = TRUE, lambda 1se", 
                       "Relaxed LASSO implementation no CV", "Relaxed LASSO implementation CV", 
                       "Post LASSO lambda min", "Post LASSO lambda 1se")
  
  # Create dataframes to keep track of coefficient values and MSEs per each iteration of simulation
  coefficient_values = data.frame(matrix(nrow = 0, ncol = length(coefficient_names)))

  col_names = rownames(as.data.frame.matrix(coef(resulting_fits$cv_glmnet_relaxed)))
  coef_values = as.numeric(coef(resulting_fits$post_lasso_lambda_min))
  coef_names = rownames(coef(resulting_fits$post_lasso_lambda_min))
  names(coef_values) = coef_names
  y_post_lasso_lambda_min_coefficient_row = formatCoefficientTableRow(coef_values, col_names)
  
  coef_values = as.numeric(coef(resulting_fits$post_lasso_lambda_1se))
  coef_names = rownames(coef(resulting_fits$post_lasso_lambda_1se))
  names(coef_values) = coef_names
  y_post_lasso_lambda_1se_coefficient_row = formatCoefficientTableRow(coef_values, col_names)

  
  coefficient_values = rbind(coefficient_values, 
                             c(0, resulting_fits$cv_glmnet$glmnet.fit$beta[, resulting_fits$cv_glmnet$index[1]]),
                             c(0, coef(resulting_fits$cv_glmnet)[-1]),
                             c(0, resulting_fits$cv_glmnet_relaxed$glmnet.fit$relaxed$beta[, resulting_fits$cv_glmnet_relaxed$relaxed$index[1]]),
                             c(0, coef(resulting_fits$cv_glmnet_relaxed)[-1]),
                             c(0, resulting_fits$my_relaxed$coefficients[resulting_fits$my_relaxed$min_lambda_index, -1]),
                             c(0, resulting_fits$my_relaxed_cv$coefficients[resulting_fits$my_relaxed_cv$min_lambda_index, -1]),
                             c(0, y_post_lasso_lambda_min_coefficient_row),
                             c(0, y_post_lasso_lambda_1se_coefficient_row))
  
  options(digits = 5)
  colnames(coefficient_values) = coefficient_names
  coefficient_values[, 1] = model_fit_labels
  
  return(coefficient_values)
}




runSim = function(p, n, N, print_time) {
  # Generate/split data
  dataset = generateDataset(p, n)
  partitioned_data = partitionData(dataset$X, dataset$Y)
  test_data = partitioned_data[c("x_test", "y_test")]
  
  sim_replicates = replicate(N, {
    dataset = generateDataset(p, n)
    partitioned_data = partitionData(dataset$X, dataset$Y)
    training_data = partitioned_data[c("x_train", "y_train")]
    
    result_one_iter = oneIteration(p, n, training_data, test_data, print_time)

    result = list(coefficient_table = result_one_iter[[1]], MSE_table = result_one_iter[[2]])
    
    return(result)
    
  }, simplify = FALSE)
  
  # writeLines("")
  # print(class(sim_replicates[[1]][[2]]))
  # writeLines("")
  # print(sim_replicates[[1]][[2]])
  # writeLines("")
  # print(class(sim_replicates[2]))
  # writeLines("")
  # print(sim_replicates[2])
  
  sim_coefficient_results = data.frame(matrix(nrow = 0, ncol = ncol(sim_replicates[[1]][[1]])))
  sim_MSE_results = data.frame(matrix(nrow = 0, ncol = ncol(sim_replicates[[1]][[2]])))

  for(i in c(1:N)) {
    sim_coefficient_results = rbind(sim_coefficient_results, sim_replicates[[i]][[1]])
    sim_MSE_results = rbind(sim_MSE_results, sim_replicates[[i]][[2]])
  }

  # sim_coefficient_results = do.call(rbind, sim_replicates[1])
  # sim_MSE_results = do.call(rbind, sim_replicates[2])
  return(list(sim_coefficient_table = sim_coefficient_results, sim_MSE_table = sim_MSE_results))
}


sim_results = runSim(20, 400, 1000, TRUE)


```


# Results from N = 1000 simulation

### Coefficient Biases

``` {r resulting-coefficients, echo=FALSE}
round_df = function(x, digits) {
    # round all numeric variables
    # x: data frame 
    # digits: number of digits to round
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x
}

betas = c()
p = 20
for (i in seq(1:p)) {
    if (i %% 2 != 0) {
        betas = c(betas, 0)
    } else {
        betas = c(betas, 0.5)
    }
}

model_fit_labels = c("cv.glmnet relax = FALSE, LASSO, lambda min", "cv.glmnet relax = FALSE, LASSO, lambda 1se", 
                       "cv.glmnet relax = TRUE, lambda min", "cv.glmnet relax = TRUE, lambda 1se", 
                       "Relaxed LASSO implementation no CV", "Relaxed LASSO implementation CV", 
                       "Post LASSO lambda min", "Post LASSO lambda 1se")

bias_table = data.frame(matrix(nrow = 0, ncol = length(sim_results$sim_coefficient_table)))
coefficient_names = colnames(as.data.frame(sim_results$sim_coefficient_table))
colnames(bias_table) = coefficient_names

for (i in model_fit_labels) {
  average_coef_row = colMeans((sim_results$sim_coefficient_table %>% filter(Model == i))[, -1])
  average_coef_row = average_coef_row - betas
  bias_table = rbind(bias_table, c(i, average_coef_row))
}
colnames(bias_table) = coefficient_names
bias_table[, -1] = lapply(bias_table[, -1], as.numeric)

options(digits = 5)

bias_table[, -1] = round_df(bias_table[, -1], 3)

bias_table
```

### Average Test MSEs

``` {r resulting-MSEs, echo=FALSE}

MSE_labels = c("cv.glmnet relax = FALSE, LASSO, lambda min", "cv.glmnet relax = FALSE, LASSO, lambda 1se", 
                       "cv.glmnet relax = TRUE, lambda min", "cv.glmnet relax = TRUE, lambda 1se", 
                       "Relaxed LASSO implementation no CV", "Relaxed LASSO implementation CV")

average_MSE_table = data.frame(matrix(nrow = 0, ncol = 2))
colnames(average_MSE_table) = c("Model", "Test MSE")

for (i in MSE_labels) {
  average_MSE_row = mean((sim_results$sim_MSE_table %>% filter(Model == i))[, -1])
  average_MSE_table = rbind(average_MSE_table, c(i, average_MSE_row))
}
colnames(average_MSE_table) = c("Model", "Test MSE")
average_MSE_table[, -1] = as.numeric(average_MSE_table[, -1])
options(digits = 5)

average_MSE_table
```

# CV MSE plot by log lambda

``` {r relaxed-lasso-glmnet-cv-results, echo=FALSE, eval = FALSE}
par(mfrow = c(1, 1), mar = c(2, 4, 6, 4))
plot(fit_Y1, main = "relax = FALSE, LASSO")
plot(relaxed_fit_Y1, main = "relax = TRUE")
```

