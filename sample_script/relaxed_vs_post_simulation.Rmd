---
title: "Relaxed Lasso Glmnet Simulation"
author: "Alexander Romanus"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
library(casebase)
library(future.apply)
library(glmnet)
#library(mtool)
library(parallelly)
library(timereg)
library(parallel)
library(tictoc)
library(tidyverse)
#library(riskRegression)
library(cmprsk)
library(survsim)
library(caret)
library(Matrix)

# Helper functions 
source("src/helper_functions.R")
```

# Simulation setup

```{r setting-up-simulation}
generateDataset = function(p, n) {
  beta = c()
  for (i in seq(1:(p+1))) {
    if (i == 1) {
      beta = c(beta, 1)
    }
    else if (i %% 2 == 0) {
      beta = c(beta, 0)
    } else {
      beta = c(beta, 0.5)
    }
  }
  beta = as.matrix(beta)
  beta_neg = -beta
  
  
  zero_ind1 <- which(beta == 0)
  nonzero_ind1 <- which(beta != 0)
  
  
  # Generate X (iid case)
  X <- matrix(rnorm(n*p), nrow = n, ncol = p)
  X = cbind(rep(1, times = n), X)
  
  
  #Generate Y
  epsilon <- rnorm(n, sd = 0.5)
  Y1 = X %*% beta + epsilon
  Y2 = X %*% beta_neg + epsilon
  
  result = list(X = X, Y = Y1)
  return(result)
}
```

``` {r train-test-split, echo=FALSE, include = FALSE}
partitionData = function(x, y) {
  train_index_y = caret::createDataPartition(y, p = 0.80, list = FALSE)

  x_train = x[train_index_y, -1]
  y_train = y[train_index_y]

  x_test = x[-train_index_y, -1]
  y_test = y[-train_index_y]

  result = list(x_train = x_train, y_train = y_train,
                x_test = x_test, y_test = y_test)
  
  return(result)
}
```

# Fits

``` {r different-models-fits, echo=FALSE, include = FALSE, eval = FALSE}
fitAll = function(train_data, response, print_time) {
  fit_Y1 = cv.glmnet(train_data, response, gamma = 0, relax = FALSE)
  relaxed_fit_Y1 = cv.glmnet(train_data, response, gamma = 0, relax = TRUE)
  my_relaxed_fit_Y1 = myRelaxed(train_data, response, FALSE, print_time)
  my_relaxed_fit_cv_Y1 = myRelaxed(train_data, response, TRUE, print_time)
  
  coef_lasso_same_lambda = as.data.frame.matrix(coef(fit_Y1))[-1, ]
  non_zero_coef_lasso_then_OLS_same_lambda = coef_lasso_same_lambda[coef_lasso_same_lambda != 0]
  non_zero_coef_lasso_then_OLS_same_lambda_indeces = which(coef_lasso_same_lambda %in% non_zero_coef_lasso_then_OLS_same_lambda)
  
  lambda_min = fit_Y1$lambda.min
  lambda_1se = fit_Y1$lambda.1se
  
  coefficient_names = colnames(as.data.frame(train_data))
  selected_coefficient_names = coefficient_names[non_zero_coef_lasso_then_OLS_same_lambda_indeces]
  new_train_data = train_data[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
  colnames(new_train_data) = c(selected_coefficient_names)
  
  fit_Y1_post_lasso_lambda_min = glmnet(new_train_data, response, lambda = lambda_min)
  fit_Y1_post_lasso_lambda_1se = glmnet(new_train_data, response, lambda = lambda_1se)
  
  result = list(cv_glmnet = fit_Y1, cv_glmnet_relaxed = relaxed_fit_Y1, my_relaxed = my_relaxed_fit_Y1,
                my_relaxed_cv = my_relaxed_fit_cv_Y1, post_lasso_lambda_min = fit_Y1_post_lasso_lambda_min,
                post_lasso_lambda_1se = fit_Y1_post_lasso_lambda_1se)
  
  return(result)
}


dataset = generateDataset(20, 400)
partitioned_data = partitionData(dataset$X, dataset$Y)
training_data = partitioned_data[c("x_train", "y_train")]
resulting_fits = fitAll(training_data$x_train, training_data$y_train, FALSE)

```

# Run simulation
``` {r run-sim}

# dataset = generateDataset(20, 400)
# partitioned_data = partitionData(dataset$X, dataset$Y)
# training_data = partitioned_data[c("x_train", "y_train")]
# test_data = partitioned_data[c("x_test", "y_test")]
# resulting_fits = fitAll(training_data$x_train, training_data$y_train, FALSE)

getTestSet = function(p, n) {
  # Get test set
  dataset = generateDataset(p, n)
  partitioned_data = partitionData(dataset$X, dataset$Y)
  test_data = partitioned_data[c("x_test", "y1_test")]
  return(test_data)
}

oneIteration = function(p, n) {
  # Create dataframes to keep track of coefficient values and MSEs per each iteration of simulation
  coefficient_names = colnames(as.data.frame(test_data$x_test))
  coefficient_names = c("Model fitting procedure", coefficient_names)
  coefficient_values_final = data.frame(matrix(nrow = 0, ncol = length(coefficient_names)))
  colnames(coefficient_values_final) = coefficient_names
  model_fit_labels = c("cv.glmnet relax = FALSE, LASSO, lambda min", "cv.glmnet relax = FALSE, LASSO, lambda 1se", "cv.glmnet relax = TRUE, lambda min", "cv.glmnet relax = TRUE, lambda 1se", "Relaxed LASSO implementation no CV",
                     "Relaxed LASSO implementation CV", "Post LASSO lambda min", "Post LASSO lambda 1se")
    
  for(i in c(1:N)) {
    tryCatch({
      print(paste("iteration: ", i))
      writeLines("")
      
      # Get train-test sets
      dataset = generateDataset(20, 400)
      partitioned_data = partitionData(dataset$X, dataset$Y)
      training_data = partitioned_data[c("x_train", "y_train")]
      resulting_fits = fitAll(training_data$x_train, training_data$y_train, FALSE)
      
      coefficient_values = data.frame(matrix(nrow = 0, ncol = length(coefficient_names)))
      colnames(coefficient_values) = coefficient_names
      
      col_names = rownames(as.data.frame.matrix(coef(resulting_fits$cv_glmnet_relaxed)))
      coef_values = as.numeric(coef(resulting_fits$post_lasso_lambda_min))
      coef_names = rownames(coef(resulting_fits$post_lasso_lambda_min))
      names(coef_values) = coef_names
      Y1_post_lasso_lambda_min_coefficient_row = formatCoefficientTableRow(coef_values, col_names)
      
      coef_values = as.numeric(coef(resulting_fits$post_lasso_lambda_1se))
      coef_names = rownames(coef(resulting_fits$post_lasso_lambda_1se))
      names(coef_values) = coef_names
      Y1_post_lasso_lambda_1se_coefficient_row = formatCoefficientTableRow(coef_values, col_names)
    
      
      coefficient_values = rbind(coefficient_values, 
                                 c(0, resulting_fits$cv_glmnet$glmnet.fit$beta[, resulting_fits$cv_glmnet$index[1]]),
                                 c(0, coef(resulting_fits$cv_glmnet)[-1]),
                                 c(0, resulting_fits$cv_glmnet_relaxed$glmnet.fit$relaxed$beta[, resulting_fits$cv_glmnet_relaxed$relaxed$index[1]]),
                                 c(0, coef(resulting_fits$cv_glmnet_relaxed)[-1]),
                                 c(0, resulting_fits$my_relaxed$coefficients[resulting_fits$my_relaxed$min_lambda_index, -1]),
                                 c(0, resulting_fits$my_relaxed_cv$coefficients[resulting_fits$my_relaxed_cv$min_lambda_index, -1]),
                                 c(0, Y1_post_lasso_lambda_min_coefficient_row),
                                 c(0, Y1_post_lasso_lambda_1se_coefficient_row))
      
      print(coefficient_values)
    
      if(i == 1) {
        coefficient_values_final = coefficient_values
      } else {
        # print(coefficient_values)
        # print(coefficient_values_final)
        # create a new variable from the rownames
        coefficient_values$rn <- rownames(coefficient_values)
        coefficient_values_final$rn <- rownames(coefficient_values_final)
        
        # bind the two dataframes together by row and aggregate
        res <- aggregate(cbind(coefficient_names) ~ rn, rbind(coefficient_values,coefficient_values_final), sum)
        # or (thx to @alistaire for reminding me):
        res <- aggregate(. ~ rn, rbind(coefficient_values,coefficient_values_final), sum)
        
        # assign the rownames again
        rownames(res) <- res$rn
        
        # get rid of the 'rn' column
        res <- res[, -1]
    
        
        coefficient_values_final = res
      }
      print(coefficient_values_final)
    
      
    },
    error = function(e) {
      print(e)
    }
    )
  }
  
  options(digits = 5)
  
  coefficient_values_final[, 1] = model_fit_labels
  print(coefficient_values_final)
  
}

runSim = function(p, n, N) {

  test_data = getTestSet(p, n)
  
  replicate(N, {
    oneIteration(p, n)
    
    
  })


```


# Results

### Coefficients

``` {r resulting-coefficients, echo=FALSE}
coefficient_names = colnames(as.data.frame(x_train))
coefficient_names = c("Model fitting procedure", coefficient_names)
coefficient_values = data.frame(matrix(nrow = 0, ncol = length(coefficient_names) + 1))

col_names = rownames(as.data.frame.matrix(coef(relaxed_fit_Y1)))
coef_values = as.numeric(coef(fit_Y1_post_lasso_lambda_min))
coef_names = rownames(coef(fit_Y1_post_lasso_lambda_min))
names(coef_values) = coef_names
Y1_post_lasso_lambda_min_coefficient_row = formatCoefficientTableRow(coef_values, col_names)

coef_values = as.numeric(coef(fit_Y1_post_lasso_lambda_1se))
coef_names = rownames(coef(fit_Y1_post_lasso_lambda_1se))
names(coef_values) = coef_names
Y1_post_lasso_lambda_1se_coefficient_row = formatCoefficientTableRow(coef_values, col_names)



coefficient_values = rbind(coefficient_values, 
                           c(0, lapply(fit_Y1$glmnet.fit$beta[, fit_Y1$index[1]], function(x) round(x, 3))),
                           c(0, lapply(coef(fit_Y1)[-1], function(x) round(x, 3))),
                           c(0, lapply(relaxed_fit_Y1$glmnet.fit$relaxed$beta[, relaxed_fit_Y1$relaxed$index[1]], function(x) round(x, 3))),
                           c(0, lapply(coef(relaxed_fit_Y1)[-1], function(x) round(x, 3))),
                           c(0, lapply(my_relaxed_fit_Y1$coefficients[my_relaxed_fit_Y1$min_lambda_index, -1], function(x) round(x, 3))),
                           c(0, lapply(Y1_post_lasso_lambda_min_coefficient_row, function(x) round(x, 3))),
                           c(0, lapply(Y1_post_lasso_lambda_1se_coefficient_row, function(x) round(x, 3))))
                        
colnames(coefficient_values) = coefficient_names
model_fit_labels = c("cv.glmnet relax = FALSE, LASSO, lambda min", "cv.glmnet relax = FALSE, LASSO, lambda 1se", "cv.glmnet relax = TRUE, lambda min", "cv.glmnet relax = TRUE, lambda 1se", "Relaxed LASSO implementation", "Post LASSO lambda min", "Post LASSO lambda 1se")


options(digits = 5)

coefficient_values[, 1] = model_fit_labels
coefficient_values
```

### MSEs

``` {r resulting-MSEs, echo=FALSE}
pred_fit_min = predict(fit_Y1, newx = x_test, s = fit_Y1$lambda.min)
pred_fit_1se = predict(fit_Y1, newx = x_test, s = fit_Y1$lambda.1se)
pred_fit_relaxed_min = predict(relaxed_fit_Y1, newx = x_test, s = relaxed_fit_Y1$relaxed$lambda.min)
pred_fit_relaxed_1se = predict(relaxed_fit_Y1, newx = x_test, s = relaxed_fit_Y1$relaxed$lambda.1se)

pred_myRelaxed = predict(my_relaxed_fit_Y1$best_fit, newx = x_test)

coefficient_names = colnames(as.data.frame(x_test))
new_x_test = x_test[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
colnames(new_x_test) = rownames(as.data.frame.matrix(fit_Y1_post_lasso_lambda_min$beta))
pred_fit_post_lasso_min = predict(fit_Y1_post_lasso_lambda_min, newx = new_x_test, s = fit_Y1$lambda.min)


coefficient_names = colnames(as.data.frame(x_test))
new_x_test = x_test[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
colnames(new_x_test) = rownames(as.data.frame.matrix(fit_Y1_post_lasso_lambda_1se$beta))
pred_fit_post_lasso_1se = predict(fit_Y1_post_lasso_lambda_1se, newx = new_x_test, s = fit_Y1$lambda.1se)


# Compute MSE
mse_min <- sum((pred_fit_min - y1_test)^2)
mse_1se <- sum((pred_fit_1se - y1_test)^2)
mse_relaxed_min <- sum((pred_fit_relaxed_min - y1_test)^2)
mse_relaxed_1se <- sum((pred_fit_relaxed_1se - y1_test)^2)
mse_myRelaxed <- sum((pred_myRelaxed - y1_test)^2)
mse_post_lasso_min <- sum((pred_fit_post_lasso_min - y1_test)^2)
mse_post_lasso_1se <- sum((pred_fit_post_lasso_1se - y1_test)^2)

MSEs = data.frame(matrix(nrow = 7, ncol = 2))
colnames(MSEs) = c("Model fitting procedure", "Test MSE")
MSEs[, 1] = model_fit_labels
MSEs[, 2] = c(mse_min, mse_1se, mse_relaxed_min, mse_relaxed_1se, mse_relaxed_1se, mse_post_lasso_min, mse_post_lasso_1se)

MSEs

```

# CV MSE plot by log lambda

``` {r relaxed-lasso-glmnet-cv-results, echo=FALSE}
par(mfrow = c(1, 1), mar = c(2, 4, 6, 4))
plot(fit_Y1, main = "relax = FALSE, LASSO")
plot(relaxed_fit_Y1, main = "relax = TRUE")
```

