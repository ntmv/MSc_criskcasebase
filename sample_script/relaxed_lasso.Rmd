---
title: "Relaxed Lasso Glmnet Simulation"
author: "Alexander Romanus"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
library(casebase)
library(future.apply)
library(glmnet)
#library(mtool)
library(parallelly)
library(timereg)
library(parallel)
library(tictoc)
library(tidyverse)
#library(riskRegression)
library(cmprsk)
library(survsim)
library(caret)
library(Matrix)

# Fitting functions 
#source("src/fitting_functions.R")
```

``` {r generate-competing-risks-data, eval=FALSE, echo=FALSE, include = FALSE}
n <- 400
p <- 20
beta <- list(c(0.5, rep(0, 18), 0.5),c(0.2, rep(0, 18), 0.2))
dist.ev <- c("weibull", "weibull")
anc.ev <- c(0.8, 0.3)
beta0.ev <- c(0.1, 0.1)


# Generating survival data 
# This function is modified from the survsim package and can be found in the fitting_functions.R file sourced above
#
sim.data <- crisk.sim_mvn(n = n, p = p, rho = 0.5, foltime = 4, dist.ev = dist.ev, 
                      anc.ev = anc.ev, beta0.ev = beta0.ev, beta0.cens = 0.05, anc.cens = 4, nsit = 2, 
                      beta = beta)

# fix status variable
sim.data$cause <- with(sim.data, ifelse(is.na(sim.data$cause), 0, sim.data$cause))
colnames(sim.data)[grepl("x", colnames(sim.data))]   <- paste0("X", seq_len(p))

# Format data
sim.data <- sim.data %>%
  select(-nid, -status, -start, -stop, -z) %>%
  rename(status = cause)

# Average estimates of incidence and censoring rate
prop.table(table(sim.data$status))

# True cumulative incidence 
cif <- cuminc(ftime = sim.data$time, fstatus = sim.data$status)
cif
```

``` {r train-test-split-and-formatting, eval=FALSE, echo=FALSE}
#################################################################
# Split into training and validation sets (stratified)
train.index <- caret::createDataPartition(sim.data$status, p = 0.80, list = FALSE)
train <- sim.data[train.index,]
test <- sim.data[-train.index,]
######################### Cause-specific proportional hazards model ###############
# Censor competing event
y_train <- Surv(time = train$time, event = train$status == 1)

x_train <- model.matrix(~ . -time -status, data = train)[, -1] 

# Censor competing event
y_test <- Surv(time = test$time, event = test$status == 1)

x_test <- model.matrix(~ . -time -status, data = test)[, -1]
```

``` {r generate-case-base-data, include = FALSE, eval=FALSE, echo=FALSE}
surv_obj_train <- with(train, Surv(time, as.numeric(status), type = "mstate"))

cov_train <- as.matrix(cbind(train[, c(grepl("X", colnames(train)))], time = log(train$time)))

# Create case-base dataset
cb_data_train <- create_cbDataset(surv_obj_train, cov_train, ratio = 10)
```

``` {r fit-multinomial-logistic-to-hazard, eval=FALSE, echo=FALSE, include = FALSE}
tic()
cv.alpha <- mtool.multinom.cv(cb_data_train, lambda_max = 0.3, alpha = 1, nfold = 10)
toc()

cv.alpha
```


``` {r results, eval=FALSE, echo=FALSE, include = FALSE}
# Cross-validation plot 
p1 <- plot_cv.multinom(cv.alpha$deviance_grid, cv.alpha$lambdagrid, cv.alpha$lambda.min, cv.alpha$lambda.1se, nfold = 10)

# validation set
surv_obj_val <- with(test, Surv(time, as.numeric(status), type = "mstate"))

# Covariance matrix
cov_val <- cbind(test[, c(grepl("X", colnames(test)))], time = log(test$time))

# Case-base dataset
cb_data_val <- create_cbDataset(surv_obj_val, as.matrix(cov_val))
```

``` {r relaxed-simulation-train-test-split, echo = FALSE}
data(QuickStartExample)
set.seed(2023)

train.index = caret::createDataPartition(QuickStartExample$y, p = 0.80, list = FALSE)

x_train = QuickStartExample$x[train.index,]
y_train = QuickStartExample$y[train.index,]

x_test = QuickStartExample$x[-train.index,]
y_test = QuickStartExample$y[-train.index,]
```

```{r setup-coefficient-results-table, echo = FALSE}
coefficient_names = colnames(as.data.frame(x_train))

coefficient_names = c("Model fitting procedure", coefficient_names)

coefficient_values = data.frame(matrix(nrow = 0, ncol = length(coefficient_names) + 1))
colnames(coefficient_values) = coefficient_names
model_fit_labels = c("CV, lambda min, relax = TRUE", "CV, lambda 1se, relax = TRUE", "lasso noCV, lambda 1se from relax = TRUE, relax = FALSE, then ridge", "lasso CV, lambda 1se from CV, relax = FALSE, then ridge", "lasso noCV, lambda 1se from relax = TRUE, relax = FALSE, then OLS", "lasso CV, lambda 1se from CV, relax = FALSE, then OLS", "lasso noCV relax = FALSE, then OLS fit on selected predictors from every lambda", "lasso CV relax = FALSE, then OLS fit on selected predictors from every lambda")

### Fit lasso with lambda value found during cross validation, then OLS


#row.names(coefficient_values) = model_fit_labels
```

# Fits

### Fit glmnet with relax = TRUE

``` {r glmnet-relaxed-true-baseline, echo = FALSE}
set.seed(2023)
fit_relaxed = glmnet(x_train, y_train, gamma = 0, relax = TRUE)
cv_fit_relaxed = cv.glmnet(x_train, y_train, gamma = 0, relax = TRUE)

cv_lambda_relaxed_min = cv_fit_relaxed$relaxed$lambda.min
cv_lambda_relaxed_1se = cv_fit_relaxed$relaxed$lambda.1se
cv_lambda_min_index = cv_fit_relaxed$relaxed$index[1]
cv_lambda_1se_index = cv_fit_relaxed$relaxed$index[2]

coef_cv_fit_relaxed_1se = cv_fit_relaxed$glmnet.fit$relaxed$beta[, cv_lambda_1se_index]
coef_cv_fit_relaxed_min = cv_fit_relaxed$glmnet.fit$relaxed$beta[, cv_lambda_min_index]

non_zero_coef_relaxed_1se = coef_cv_fit_relaxed_1se[coef_cv_fit_relaxed_1se != 0]
non_zero_coef_relaxed_1se_indeces = which(coef_cv_fit_relaxed_1se %in% non_zero_coef_relaxed_1se)

non_zero_coef_relaxed_min = coef_cv_fit_relaxed_min[coef_cv_fit_relaxed_min != 0]
non_zero_coef_relaxed_min_indeces = which(coef_cv_fit_relaxed_min %in% non_zero_coef_relaxed_min)

# new_x_train = x_train[, non_zero_coef_relaxed_indeces]
# #relaxed_then_OLS = lm(y_train~new_x_train)
# 
# 
# attempt1 = cv.glmnet(x_train, y_train, family="gaussian", relax = FALSE, alpha = 1)
# lambda_min = attempt1$lambda.min
# lambda_1se = attempt1$lambda.1se



coefficient_values = rbind(coefficient_values, c(0, lapply(coef_cv_fit_relaxed_min, function(x) round(x, 3))), c(0, lapply(coef_cv_fit_relaxed_1se, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```


### Fit lasso with lambda 1se value as was found during cross validation using relax = TRUE, then ridge

``` {r lasso-same-lambda-then-ridge, echo = FALSE}
set.seed(2023)
fit_lasso_same_lambda = glmnet(x_train, y_train, family="gaussian", alpha=1, lambda = cv_lambda_relaxed_1se)

coef_fit_lasso_same_lambda = as.data.frame.matrix(coef(fit_lasso_same_lambda))[-1, ]
non_zero_coef = coef_fit_lasso_same_lambda[coef_fit_lasso_same_lambda != 0]

non_zero_coef_lasso_same_lambda_indeces = which(coef_fit_lasso_same_lambda %in% non_zero_coef)

new_x_train = x_train[, non_zero_coef_lasso_same_lambda_indeces]

fit_lasso_then_ridge_same_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0)
coef_lasso_then_ridge_same_lambda = coef(fit_lasso_then_ridge_same_lambda)

coef_lasso_then_ridge_same_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_lasso_same_lambda_indeces){
    coef_lasso_then_ridge_same_lambda_final[i] = non_zero_coef[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_ridge_same_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso with lambda value found during cross validation, then ridge

``` {r lasso-cv-lambda-then-ridge, echo = FALSE}
set.seed(2023)
fit_lasso_cv_lambda = cv.glmnet(x_train, y_train, family="gaussian", alpha=1)

coef_fit_lasso_cv_lambda = as.data.frame.matrix(coef(fit_lasso_cv_lambda))[-1, ]
non_zero_coef = coef_fit_lasso_cv_lambda[coef_fit_lasso_cv_lambda != 0]

# best_fit_index = fit_lasso_cv_lambda$index[2]
# non_zero_coef_indeces = which(as.list(fit_lasso_cv_lambda$glmnet.fit$beta[, best_fit_index]) %in% non_zero_coef)
non_zero_coef_lasso_cv_lambda_indeces = which(coef_fit_lasso_cv_lambda %in% non_zero_coef)

new_x_train = x_train[, non_zero_coef_lasso_cv_lambda_indeces]

fit_lasso_then_ridge_cv_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0)
coef_lasso_then_ridge_cv_lambda = coef(fit_lasso_then_ridge_cv_lambda)


coef_lasso_then_ridge_cv_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_lasso_cv_lambda_indeces){
    coef_lasso_then_ridge_cv_lambda_final[i] = non_zero_coef[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_ridge_cv_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso with same lambda.min value as was found during cross validation using relax = TRUE, then OLS

``` {r lasso-same-lambda-then-OLS, echo = FALSE}
set.seed(2023)
fit_lasso_same_lambda = glmnet(x_train, y_train, family="gaussian", alpha=1, lambda = cv_lambda_relaxed_1se)

coef_lasso_same_lambda = as.data.frame.matrix(coef(fit_lasso_same_lambda))[-1, ]
non_zero_coef_lasso_then_OLS_same_lambda = coef_lasso_same_lambda[coef_lasso_same_lambda != 0]

non_zero_coef_lasso_then_OLS_same_lambda_indeces = which(coef_lasso_same_lambda %in% non_zero_coef_lasso_then_OLS_same_lambda)

new_x_train = x_train[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]

fit_lasso_then_OLS_same_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0, lambda=0)
coef_lasso_then_OLS_same_lambda = coef(fit_lasso_then_OLS_same_lambda)

fit_lasso_then_OLS_same_lambda_lm = lm(y_train~new_x_train)
coef_lasso_then_OLS_same_lambda_lm = coef(fit_lasso_then_OLS_same_lambda_lm)

coef_lasso_then_OLS_same_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_lasso_then_OLS_same_lambda_indeces){
    coef_lasso_then_OLS_same_lambda_final[i] = non_zero_coef_lasso_then_OLS_same_lambda[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_OLS_same_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso with lambda value found during cross validation, then OLS

``` {r lasso-cv-lambda-then-OLS, echo = FALSE}
set.seed(2023)
fit_lasso_cv_lambda = cv.glmnet(x_train, y_train, family="gaussian", alpha=1)

# fit_lasso_cv_lambda$lambda.min
# 
# try_relax_hopefully = glmnet(x_train, y_train, lambda=fit_lasso_cv_lambda$lambda.min)
# coef(try_relax_hopefully)
# 
# coef(fit_lasso_cv_lambda, s="lambda.min")


coef_fit_lasso_cv_lambda = as.data.frame.matrix(coef(fit_lasso_cv_lambda))[-1, ]
non_zero_coef_lasso_cv_then_OLS = coef_fit_lasso_cv_lambda[coef_fit_lasso_cv_lambda != 0]

# best_fit_index = fit_lasso_cv_lambda$index[2]
# non_zero_coef_indeces = which(as.list(fit_lasso_cv_lambda$glmnet.fit$beta[, best_fit_index]) %in% non_zero_coef)
non_zero_coef_lasso_cv_then_OLS_indeces = which(coef_fit_lasso_cv_lambda %in% non_zero_coef_lasso_cv_then_OLS)


new_x_train = x_train[, non_zero_coef_lasso_cv_then_OLS_indeces]

fit_lasso_then_OLS_cv_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0, lambda=0)
coef_lasso_then_OLS_cv_lambda = coef(fit_lasso_then_OLS_cv_lambda)

coef_lasso_then_OLS_cv_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_lasso_cv_then_OLS_indeces){
    coef_lasso_then_OLS_cv_lambda_final[i] = non_zero_coef_lasso_cv_then_OLS[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_OLS_cv_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso without cross validation, then OLS on all lambda values
Per meeting on June 15th, tried fitting LASSO in first iteration without cross validation, took sets of predictors selected with each lambda value tried, then fit OLS on each of those sets, taking the OLS fit with the lowest MSE as the best fit.

``` {r lasso-then-ols-all-predictors, echo = FALSE}
set.seed(2023)
fit_lasso = glmnet(x_train, y_train, family="gaussian", alpha=1)

all_coef_fit_lasso = as.data.frame.matrix(coef(fit_lasso))[-1, ]

current_MSE = .Machine$double.xmax;
best_fit = lm(1~1)
non_zero_coef_lasso_then_OLS_all_predictors_indeces_best_fit = c()

for(i in (1: length(all_coef_fit_lasso))) {
  current_coef = all_coef_fit_lasso[i]
  non_zero_coef_lasso_then_OLS_all_predictors = all_coef_fit_lasso[i][all_coef_fit_lasso[i] != 0]
  if (length(non_zero_coef_lasso_then_OLS_all_predictors) == 0){
    next
  }
  
  non_zero_coef_lasso_then_OLS_all_predictors_indeces = which(current_coef != 0)
  
  new_x_train = x_train[, non_zero_coef_lasso_then_OLS_all_predictors_indeces]
  
  fit_OLS_on_LASSO_subset = lm(y_train~new_x_train)
  coef_fit_OLS_on_LASSO_subset = coef(fit_OLS_on_LASSO_subset)
  
  #CHANGE THIS
  coef_fit_OLS_on_LASSO_subset = coef_fit_OLS_on_LASSO_subset[-1]

  RSS <- c(crossprod(fit_OLS_on_LASSO_subset$residuals))
  MSE <- RSS / length(fit_OLS_on_LASSO_subset$residuals)
  
  if(MSE < current_MSE) {
    current_MSE = MSE
    best_fit = fit_OLS_on_LASSO_subset
    
    # #CHANGE THIS
    # non_zero_coef_lasso_then_OLS_all_predictors_indeces = non_zero_coef_lasso_then_OLS_all_predictors_indeces[-1] - 1;
    
    non_zero_coef_lasso_then_OLS_all_predictors_indeces_best_fit = non_zero_coef_lasso_then_OLS_all_predictors_indeces

    
    coef_lasso_then_OLS_all_predictors_final = rep(0, 20)
    j = 1
    for (l in c(1:20)) {
      if (l %in% non_zero_coef_lasso_then_OLS_all_predictors_indeces){
        coef_lasso_then_OLS_all_predictors_final[l] = coef_fit_OLS_on_LASSO_subset[j]
        j = j + 1
      }
    }
  }
}

fit_lasso_then_OLS_all_predictors = best_fit


coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_OLS_all_predictors_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```


### Fit lasso with cross validation, then OLS on all lambda values
Same fit as above but LASSO fit in first iteration is done with cross validation

``` {r lasso-cv-then-ols-all-predictors, echo = FALSE}
set.seed(2023)
fit_lasso_cv = cv.glmnet(x_train, y_train, family="gaussian", alpha=1)

all_coef_fit_lasso_cv = as.data.frame.matrix(fit_lasso_cv$glmnet.fit$beta)

current_MSE = .Machine$double.xmax;
best_fit = lm(1~1)
non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces_best_fit = c()

for(i in (1: length(all_coef_fit_lasso_cv))) {
  current_coef_cv = all_coef_fit_lasso_cv[i]
  non_zero_coef_lasso_cv_then_OLS_all_predictors = all_coef_fit_lasso_cv[i][all_coef_fit_lasso_cv[i] != 0]
  if (length(non_zero_coef_lasso_cv_then_OLS_all_predictors) == 0){
    next
  }
  
  non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces = which(current_coef_cv != 0)
  
  new_x_train = x_train[, non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces]
  
  fit_OLS_on_LASSO_cv_subset = lm(y_train~new_x_train)
  coef_fit_OLS_on_LASSO_cv_subset = coef(fit_OLS_on_LASSO_cv_subset)
  
  #CHANGE THIS
  coef_fit_OLS_on_LASSO_cv_subset = coef_fit_OLS_on_LASSO_cv_subset[-1]

  RSS <- c(crossprod(fit_OLS_on_LASSO_cv_subset$residuals))
  MSE <- RSS / length(fit_OLS_on_LASSO_cv_subset$residuals)
  
  if(MSE < current_MSE) {
    current_MSE = MSE
    best_fit = fit_OLS_on_LASSO_cv_subset
    # #CHANGE THIS
    # non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces = non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces[-1] - 1;
    
    non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces_best_fit = non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces
    

    coef_lasso_cv_then_OLS_all_predictors_final = rep(0, 20)
    j = 1
    for (l in c(1:20)) {
      if (l %in% non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces){
        coef_lasso_cv_then_OLS_all_predictors_final[l] = coef_fit_OLS_on_LASSO_cv_subset[j]
        j = j + 1
      }
    }
  }
}

fit_lasso_cv_then_OLS_all_predictors = best_fit

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_cv_then_OLS_all_predictors_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

# Results

## Coefficient values of fitting procedures

``` {r relaxed-lasso-glmnet-implementation-coefficient-values, echo=FALSE}
options(digits = 5)

# coefficient_values2 <- as.data.frame(lapply(coefficient_values, FUN = function(x) {sapply(x, FUN = function(y) if(y == 0.000) {y = 0})}))

coefficient_values[, 1] = model_fit_labels

coefficient_values
```


## R-squared values of fitting procedures

``` {r relaxed-lasso-glmnet-implementation-R-squared-values, echo=FALSE, eval=FALSE}

# Compute R-squared
R_squared_relaxed_min <- round(cv_fit_relaxed$glmnet.fit$relaxed$dev.ratio[lambda_min_index], 3)
R_squared_relaxed_1se <- round(cv_fit_relaxed$glmnet.fit$relaxed$dev.ratio[lambda_1se_index], 3)
R_squared_lasso_then_ridge_same_lambda <- round(fit_lasso_then_ridge_same_lambda$dev.ratio, 3)
R_squared_lasso_then_ridge_cv_lambda <- round(fit_lasso_then_ridge_cv_lambda$dev.ratio, 3)
R_squared_lasso_then_OLS_same_lambda <- round(fit_lasso_then_OLS_same_lambda$dev.ratio, 3)
R_squared_lasso_then_OLS_cv_lambda <- round(fit_lasso_then_OLS_cv_lambda$dev.ratio, 3)



R_squared_values = data.frame(matrix(nrow = 6, ncol = 2))
colnames(R_squared_values) = c("Model fitting procedure", "R-squared")
R_squared_values[, 1] = model_fit_labels
R_squared_values[, 2] = c(R_squared_relaxed_min, R_squared_relaxed_1se, R_squared_lasso_then_ridge_same_lambda, R_squared_lasso_then_ridge_cv_lambda, R_squared_lasso_then_OLS_same_lambda, R_squared_lasso_then_OLS_cv_lambda)

R_squared_values
```

## Test MSE values

``` {r relaxed-lasso-glmnet-implementation-AIC-BIC-values, echo=FALSE}
# pred_fit_relaxed_1se = predict(cv_fit_relaxed, newx = x_test, s = lambda_relaxed_1se)
# pred_fit_relaxed_min = predict(cv_fit_relaxed, newx = x_test, s = lambda_relaxed_min)
pred_fit_relaxed_1se = predict(cv_fit_relaxed, newx = x_test, s = cv_lambda_relaxed_1se)
pred_fit_relaxed_min = predict(cv_fit_relaxed, newx = x_test, s = cv_lambda_relaxed_min)

new_x_test = x_test[, non_zero_coef_lasso_same_lambda_indeces]
pred_fit_lasso_then_ridge_same_lambda = predict(fit_lasso_then_ridge_same_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_cv_lambda_indeces]
pred_fit_lasso_then_ridge_cv_lambda = predict(fit_lasso_then_ridge_cv_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_then_OLS_same_lambda_indeces]
pred_fit_lasso_then_OLS_same_lambda = predict(fit_lasso_then_OLS_same_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_cv_then_OLS_indeces]
pred_fit_lasso_then_OLS_cv_lambda = predict(fit_lasso_then_OLS_cv_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_then_OLS_all_predictors_indeces_best_fit]
pred_fit_lasso_then_OLS_all_predictors = predict(fit_lasso_then_OLS_all_predictors, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_cv_then_OLS_all_predictors_indeces_best_fit]
pred_fit_lasso_cv_then_OLS_all_predictors = predict(fit_lasso_cv_then_OLS_all_predictors, newx = new_x_test)


# Compute MSE
mse_relaxed_min <- sum((pred_fit_relaxed_min - y_test)^2)
mse_relaxed_1se <- sum((pred_fit_relaxed_1se - y_test)^2)
mse_lasso_then_ridge_same_lambda <- sum((pred_fit_lasso_then_ridge_same_lambda - y_test)^2)
mse_lasso_then_ridge_cv_lambda <- sum((pred_fit_lasso_then_ridge_cv_lambda - y_test)^2)
mse_lasso_then_OLS_same_lambda <- sum((pred_fit_lasso_then_OLS_same_lambda - y_test)^2)
mse_lasso_then_OLS_cv_lambda <- sum((pred_fit_lasso_then_OLS_cv_lambda - y_test)^2)
mse_lasso_then_OLS_all_predictors <- sum((pred_fit_lasso_then_OLS_all_predictors - y_test)^2)
mse_lasso_cv_then_OLS_all_predictors <- sum((pred_fit_lasso_cv_then_OLS_all_predictors - y_test)^2)

MSEs = data.frame(matrix(nrow = 8, ncol = 2))
colnames(MSEs) = c("Model fitting procedure", "Test MSE")
MSEs[, 1] = model_fit_labels
MSEs[, 2] = c(mse_relaxed_min, mse_relaxed_1se, mse_lasso_then_ridge_same_lambda, mse_lasso_then_ridge_cv_lambda, mse_lasso_then_OLS_same_lambda, mse_lasso_then_OLS_cv_lambda, mse_lasso_then_OLS_all_predictors, mse_lasso_cv_then_OLS_all_predictors)

MSEs

# # Compute the AIC
# aic <- n*log(rss/n) + 2*k
# 
# # Compute the "BIC"
# bic <- n*log(rss/n) + log(n)*k

```

## CV MSE plot by log lambda

``` {r relaxed-lasso-glmnet-cv-results, echo=FALSE}
par(mfrow = c(1, 1), mar = c(2, 4, 6, 4))
plot(cv_fit_relaxed, main = "relax = TRUE fit, cv lambda")
plot(fit_lasso_cv_lambda, main = "relax = FALSE fit, only lasso, cv lambda")
# plot(fit_lasso_then_ridge_cv_lambda, main = "relax = FALSE fit, lasso then ridge, lambda = 1se lambda found with cv on lasso")
# plot(fit_lasso_then_OLS_same_lambda, main = "relax = FALSE fit, lasso then OLS, lambda = relaxed lambda min")
# plot(fit_lasso_then_OLS_cv_lambda, main = "relax = FALSE fit, lasso then OLS, lambda = 1se lambda found with cv on lasso")
```



