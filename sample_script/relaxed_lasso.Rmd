---
title: "Relaxed Lasso Glmnet Simulation"
author: "Alexander Romanus"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
library(casebase)
library(future.apply)
library(glmnet)
#library(mtool)
library(parallelly)
library(timereg)
library(parallel)
library(tictoc)
library(tidyverse)
#library(riskRegression)
library(cmprsk)
library(survsim)
library(caret)
library(Matrix)

# Fitting functions 
#source("src/fitting_functions.R")
```

``` {r generate-competing-risks-data, eval=FALSE, echo=FALSE, include = FALSE}
n <- 400
p <- 20
beta <- list(c(0.5, rep(0, 18), 0.5),c(0.2, rep(0, 18), 0.2))
dist.ev <- c("weibull", "weibull")
anc.ev <- c(0.8, 0.3)
beta0.ev <- c(0.1, 0.1)


# Generating survival data 
# This function is modified from the survsim package and can be found in the fitting_functions.R file sourced above
#
sim.data <- crisk.sim_mvn(n = n, p = p, rho = 0.5, foltime = 4, dist.ev = dist.ev, 
                      anc.ev = anc.ev, beta0.ev = beta0.ev, beta0.cens = 0.05, anc.cens = 4, nsit = 2, 
                      beta = beta)

# fix status variable
sim.data$cause <- with(sim.data, ifelse(is.na(sim.data$cause), 0, sim.data$cause))
colnames(sim.data)[grepl("x", colnames(sim.data))]   <- paste0("X", seq_len(p))

# Format data
sim.data <- sim.data %>%
  select(-nid, -status, -start, -stop, -z) %>%
  rename(status = cause)

# Average estimates of incidence and censoring rate
prop.table(table(sim.data$status))

# True cumulative incidence 
cif <- cuminc(ftime = sim.data$time, fstatus = sim.data$status)
cif
```

``` {r train-test-split-and-formatting, eval=FALSE, echo=FALSE}
#################################################################
# Split into training and validation sets (stratified)
train.index <- caret::createDataPartition(sim.data$status, p = 0.80, list = FALSE)
train <- sim.data[train.index,]
test <- sim.data[-train.index,]
######################### Cause-specific proportional hazards model ###############
# Censor competing event
y_train <- Surv(time = train$time, event = train$status == 1)

x_train <- model.matrix(~ . -time -status, data = train)[, -1] 

# Censor competing event
y_test <- Surv(time = test$time, event = test$status == 1)

x_test <- model.matrix(~ . -time -status, data = test)[, -1]
```

``` {r generate-case-base-data, include = FALSE, eval=FALSE, echo=FALSE}
surv_obj_train <- with(train, Surv(time, as.numeric(status), type = "mstate"))

cov_train <- as.matrix(cbind(train[, c(grepl("X", colnames(train)))], time = log(train$time)))

# Create case-base dataset
cb_data_train <- create_cbDataset(surv_obj_train, cov_train, ratio = 10)
```

``` {r fit-multinomial-logistic-to-hazard, eval=FALSE, echo=FALSE, include = FALSE}
tic()
cv.alpha <- mtool.multinom.cv(cb_data_train, lambda_max = 0.3, alpha = 1, nfold = 10)
toc()

cv.alpha
```


``` {r results, eval=FALSE, echo=FALSE, include = FALSE}
# Cross-validation plot 
p1 <- plot_cv.multinom(cv.alpha$deviance_grid, cv.alpha$lambdagrid, cv.alpha$lambda.min, cv.alpha$lambda.1se, nfold = 10)

# validation set
surv_obj_val <- with(test, Surv(time, as.numeric(status), type = "mstate"))

# Covariance matrix
cov_val <- cbind(test[, c(grepl("X", colnames(test)))], time = log(test$time))

# Case-base dataset
cb_data_val <- create_cbDataset(surv_obj_val, as.matrix(cov_val))
```

``` {r relaxed-simulation-train-test-split, echo = FALSE}
data(QuickStartExample)
set.seed(2023)

train.index = caret::createDataPartition(QuickStartExample$y, p = 0.80, list = FALSE)

x_train = QuickStartExample$x[train.index,]
y_train = QuickStartExample$y[train.index,]

x_test = QuickStartExample$x[-train.index,]
y_test = QuickStartExample$y[-train.index,]
```

```{r setup-coefficient-results-table, echo = FALSE}
coefficient_names = colnames(as.data.frame(x_train))

coefficient_names = c("Model fitting procedure", coefficient_names)

coefficient_values = data.frame(matrix(nrow = 0, ncol = length(coefficient_names) + 1))
colnames(coefficient_values) = coefficient_names
model_fit_labels = c("CV, lambda min, relax = TRUE", "CV, lambda 1se, relax = TRUE", "lasso noCV, lambda 1se from relax = TRUE, relax = FALSE, then ridge", "lasso CV, lambda 1se from CV, relax = FALSE, then ridge", "lasso noCV, lambda 1se from relax = TRUE, relax = FALSE, then OLS", "lasso CV, lambda 1se from CV, relax = FALSE, then OLS")
#row.names(coefficient_values) = model_fit_labels
```

# Fits

### Fit glmnet with relax = TRUE

``` {r glmnet-relaxed-true-baseline, echo = FALSE}
set.seed(2023)
cv_fit_relaxed = cv.glmnet(x_train, y_train, gamma = 0, relax = TRUE)

lambda_relaxed_min = cv_fit_relaxed$relaxed$lambda.min
lambda_relaxed_1se = cv_fit_relaxed$relaxed$lambda.1se
lambda_min_index = cv_fit_relaxed$relaxed$index[1]
lambda_1se_index = cv_fit_relaxed$relaxed$index[2]


coef_fit_relaxed_1se = cv_fit_relaxed$glmnet.fit$relaxed$beta[, lambda_1se_index]
coef_fit_relaxed_min = cv_fit_relaxed$glmnet.fit$relaxed$beta[, lambda_min_index]

non_zero_coef_relaxed = coef_fit_relaxed_1se[coef_fit_relaxed_1se != 0]
non_zero_coef_relaxed_indeces = which(coef_fit_relaxed_1se %in% non_zero_coef_relaxed)

new_x_train = x_train[, non_zero_coef_relaxed_indeces]
relaxed_then_OLS = lm(y_train~new_x_train)


attempt1 = cv.glmnet(x_train, y_train, family="gaussian", relax = FALSE, alpha = 1)
lambda_min = attempt1$lambda.min
lambda_1se = attempt1$lambda.1se


coefficient_values = rbind(coefficient_values, c(0, lapply(coef_fit_relaxed_min, function(x) round(x, 3))), c(0, lapply(coef_fit_relaxed_1se, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```


### Fit lasso with lambda 1se value as was found during cross validation using relax = TRUE, then ridge

``` {r lasso-same-lambda-then-ridge, echo = FALSE}
set.seed(2023)
fit_lasso_same_lambda = glmnet(x_train, y_train, family="gaussian", alpha=1, lambda = lambda_relaxed_1se)

coef_fit_lasso_same_lambda = as.data.frame.matrix(coef(fit_lasso_same_lambda))[-1, ]
non_zero_coef = coef_fit_lasso_same_lambda[coef_fit_lasso_same_lambda != 0]

non_zero_coef_lasso_same_lambda_indeces = which(coef_fit_lasso_same_lambda %in% non_zero_coef)

new_x_train = x_train[, non_zero_coef_lasso_same_lambda_indeces]

fit_lasso_then_ridge_same_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0)
coef_lasso_then_ridge_same_lambda = coef(fit_lasso_then_ridge_same_lambda)

coef_lasso_then_ridge_same_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_lasso_same_lambda_indeces){
    coef_lasso_then_ridge_same_lambda_final[i] = non_zero_coef[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_ridge_same_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso with lambda value found during cross validation, then ridge

``` {r lasso-cv-lambda-then-ridge, echo = FALSE}
set.seed(2023)
fit_lasso_cv_lambda = cv.glmnet(x_train, y_train, family="gaussian", alpha=1)

coef_fit_lasso_cv_lambda = as.data.frame.matrix(coef(fit_lasso_cv_lambda))[-1, ]
non_zero_coef = coef_fit_lasso_cv_lambda[coef_fit_lasso_cv_lambda != 0]

# best_fit_index = fit_lasso_cv_lambda$index[2]
# non_zero_coef_indeces = which(as.list(fit_lasso_cv_lambda$glmnet.fit$beta[, best_fit_index]) %in% non_zero_coef)
non_zero_coef_lasso_cv_lambda_indeces = which(coef_fit_lasso_cv_lambda %in% non_zero_coef)

new_x_train = x_train[, non_zero_coef_lasso_cv_lambda_indeces]

fit_lasso_then_ridge_cv_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0)
coef_lasso_then_ridge_cv_lambda = coef(fit_lasso_then_ridge_cv_lambda)


coef_lasso_then_ridge_cv_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_lasso_cv_lambda_indeces){
    coef_lasso_then_ridge_cv_lambda_final[i] = non_zero_coef[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_ridge_cv_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso with same lambda.min value as was found during cross validation using relax = TRUE, then OLS

``` {r lasso-same-lambda-then-OLS, echo = FALSE}
set.seed(2023)
fit_lasso_same_lambda = glmnet(x_train, y_train, family="gaussian", alpha=1, lambda = lambda_relaxed_1se)

coef_fit_lasso_same_lambda = as.data.frame.matrix(coef(fit_lasso_same_lambda))[-1, ]
non_zero_coef = coef_fit_lasso_same_lambda[coef_fit_lasso_same_lambda != 0]

non_zero_coef_indeces = which(coef_fit_lasso_same_lambda %in% non_zero_coef)
non_zero_coef_indeces

new_x_train = x_train[, non_zero_coef_indeces]

fit_lasso_then_OLS_same_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0, lambda=0)
coef_lasso_then_OLS_same_lambda = coef(fit_lasso_then_OLS_same_lambda)

fit_lasso_then_OLS_same_lambda_lm = lm(y_train~new_x_train)
coef_lasso_then_OLS_same_lambda_lm = coef(fit_lasso_then_OLS_same_lambda_lm)
coef_lasso_then_OLS_same_lambda_lm

coef_lasso_then_OLS_same_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_indeces){
    coef_lasso_then_OLS_same_lambda_final[i] = non_zero_coef[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_OLS_same_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

### Fit lasso with lambda value found during cross validation, then OLS

``` {r lasso-cv-lambda-then-OLS, echo = FALSE}
set.seed(2023)
fit_lasso_cv_lambda = cv.glmnet(x_train, y_train, family="gaussian", alpha=1)

# fit_lasso_cv_lambda$lambda.min
# 
# try_relax_hopefully = glmnet(x_train, y_train, lambda=fit_lasso_cv_lambda$lambda.min)
# coef(try_relax_hopefully)
# 
# coef(fit_lasso_cv_lambda, s="lambda.min")

coef_fit_lasso_cv_lambda = as.data.frame.matrix(coef(fit_lasso_cv_lambda))[-1, ]
non_zero_coef = coef_fit_lasso_cv_lambda[coef_fit_lasso_cv_lambda != 0]


# best_fit_index = fit_lasso_cv_lambda$index[2]
# non_zero_coef_indeces = which(as.list(fit_lasso_cv_lambda$glmnet.fit$beta[, best_fit_index]) %in% non_zero_coef)
non_zero_coef_indeces = which(coef_fit_lasso_cv_lambda %in% non_zero_coef)


new_x_train = x_train[, non_zero_coef_indeces]

fit_lasso_then_OLS_cv_lambda <- glmnet(new_x_train, y_train, family="gaussian", alpha=0, lambda=0)
coef_lasso_then_OLS_cv_lambda = coef(fit_lasso_then_OLS_cv_lambda)

coef_lasso_then_OLS_cv_lambda_final = rep(0, 20)

j = 1
for (i in c(1:20)) {
  if (i %in% non_zero_coef_indeces){
    coef_lasso_then_OLS_cv_lambda_final[i] = non_zero_coef[j]
    j = j + 1
  }
}

coefficient_values = rbind(coefficient_values, c(0, lapply(coef_lasso_then_OLS_cv_lambda_final, function(x) round(x, 3))))
colnames(coefficient_values) = coefficient_names
```

# Results

## Coefficient values of fitting procedures

``` {r relaxed-lasso-glmnet-implementation-coefficient-values, echo=FALSE}
options(digits = 5)

# coefficient_values2 <- as.data.frame(lapply(coefficient_values, FUN = function(x) {sapply(x, FUN = function(y) if(y == 0.000) {y = 0})}))

coefficient_values[, 1] = model_fit_labels

coefficient_values
```


## R-squared values of fitting procedures

``` {r relaxed-lasso-glmnet-implementation-R-squared-values, echo=FALSE, eval=FALSE}

# Compute R-squared
R_squared_relaxed_min <- round(cv_fit_relaxed$glmnet.fit$relaxed$dev.ratio[lambda_min_index], 3)
R_squared_relaxed_1se <- round(cv_fit_relaxed$glmnet.fit$relaxed$dev.ratio[lambda_1se_index], 3)
R_squared_lasso_then_ridge_same_lambda <- round(fit_lasso_then_ridge_same_lambda$dev.ratio, 3)
R_squared_lasso_then_ridge_cv_lambda <- round(fit_lasso_then_ridge_cv_lambda$dev.ratio, 3)
R_squared_lasso_then_OLS_same_lambda <- round(fit_lasso_then_OLS_same_lambda$dev.ratio, 3)
R_squared_lasso_then_OLS_cv_lambda <- round(fit_lasso_then_OLS_cv_lambda$dev.ratio, 3)


R_squared_values = data.frame(matrix(nrow = 6, ncol = 2))
colnames(R_squared_values) = c("Model fitting procedure", "R-squared")
R_squared_values[, 1] = model_fit_labels
R_squared_values[, 2] = c(R_squared_relaxed_min, R_squared_relaxed_1se, R_squared_lasso_then_ridge_same_lambda, R_squared_lasso_then_ridge_cv_lambda, R_squared_lasso_then_OLS_same_lambda, R_squared_lasso_then_OLS_cv_lambda)

R_squared_values
```

## Test MSE values

``` {r relaxed-lasso-glmnet-implementation-AIC-BIC-values, echo=FALSE}
pred_fit_relaxed_1se = predict(cv_fit_relaxed, newx = x_test, s = lambda_relaxed_1se)
pred_fit_relaxed_min = predict(cv_fit_relaxed, newx = x_test, s = lambda_relaxed_min)

new_x_test = x_test[, non_zero_coef_lasso_same_lambda_indeces]
pred_fit_lasso_then_ridge_same_lambda = predict(fit_lasso_then_ridge_same_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_cv_lambda_indeces]
pred_fit_lasso_then_ridge_cv_lambda = predict(fit_lasso_then_ridge_cv_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_same_lambda_indeces]
pred_fit_lasso_then_OLS_same_lambda = predict(fit_lasso_then_OLS_same_lambda, newx = new_x_test)

new_x_test = x_test[, non_zero_coef_lasso_cv_lambda_indeces]
pred_fit_lasso_then_OLS_cv_lambda = predict(fit_lasso_then_OLS_cv_lambda, newx = new_x_test)


# Compute MSE
mse_relaxed_min <- sum((pred_fit_relaxed_min - y_test)^2)
mse_relaxed_1se <- sum((pred_fit_relaxed_1se - y_test)^2)
mse_lasso_then_ridge_same_lambda <- sum((pred_fit_lasso_then_ridge_same_lambda - y_test)^2)
mse_lasso_then_ridge_cv_lambda <- sum((pred_fit_lasso_then_ridge_cv_lambda - y_test)^2)
mse_lasso_then_OLS_same_lambda <- sum((pred_fit_lasso_then_OLS_same_lambda - y_test)^2)
mse_lasso_then_OLS_cv_lambda <- sum((pred_fit_lasso_then_OLS_cv_lambda - y_test)^2)

MSEs = data.frame(matrix(nrow = 6, ncol = 2))
colnames(MSEs) = c("Model fitting procedure", "Test MSE")
MSEs[, 1] = model_fit_labels
MSEs[, 2] = c(mse_relaxed_min, mse_relaxed_1se, mse_lasso_then_ridge_same_lambda, mse_lasso_then_ridge_cv_lambda, mse_lasso_then_OLS_same_lambda, mse_lasso_then_OLS_cv_lambda)

MSEs

# # Compute the AIC
# aic <- n*log(rss/n) + 2*k
# 
# # Compute the "BIC"
# bic <- n*log(rss/n) + log(n)*k

```

## CV MSE plot by log lambda

``` {r relaxed-lasso-glmnet-cv-results, echo=FALSE}
par(mfrow = c(1, 1), mar = c(2, 4, 6, 4))
plot(cv_fit_relaxed, main = "relax = TRUE fit, cv lambda")
plot(fit_lasso_cv_lambda, main = "relax = FALSE fit, only lasso, cv lambda")
# plot(fit_lasso_then_ridge_cv_lambda, main = "relax = FALSE fit, lasso then ridge, lambda = 1se lambda found with cv on lasso")
# plot(fit_lasso_then_OLS_same_lambda, main = "relax = FALSE fit, lasso then OLS, lambda = relaxed lambda min")
# plot(fit_lasso_then_OLS_cv_lambda, main = "relax = FALSE fit, lasso then OLS, lambda = 1se lambda found with cv on lasso")
```


